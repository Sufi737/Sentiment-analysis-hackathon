{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove user handles\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "\n",
    "    return input_txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_emojis(tweet):\n",
    "    \"\"\"\n",
    "    In this method we are converting the emojis with the text they represent. \n",
    "    Happy emojis are converted to EMO_POS and negative to EMO_NEG.\n",
    "    \"\"\"\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "    tweet = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' smiling ', tweet)\n",
    "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "    tweet = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' laughing ', tweet)\n",
    "    # Love -- <3, :*\n",
    "    tweet = re.sub(r'(<3|:\\*)', ' love ', tweet)\n",
    "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "    tweet = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' wink ', tweet)\n",
    "    # Sad -- :-(, : (, :(, ):, )-:\n",
    "    tweet = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' sad ', tweet)\n",
    "    # Cry -- :,(, :'(, :\"(\n",
    "    tweet = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' cry ', tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to full meaningful words\n",
    "short_word_dict = {\n",
    "\"121\": \"one to one\",\n",
    "\"a/s/l\": \"age, sex, location\",\n",
    "\"ab\": \"about\",\n",
    "\"adn\": \"any day now\",\n",
    "\"afaik\": \"as far as I know\",\n",
    "\"afk\": \"away from keyboard\",\n",
    "\"aight\": \"alright\",\n",
    "\"alol\": \"actually laughing out loud\",\n",
    "\"b4\": \"before\",\n",
    "\"b4n\": \"bye for now\",\n",
    "\"bak\": \"back at the keyboard\",\n",
    "\"bf\": \"boyfriend\",\n",
    "\"bff\": \"best friends forever\",\n",
    "\"bfn\": \"bye for now\",\n",
    "\"bg\": \"big grin\",\n",
    "\"bta\": \"but then again\",\n",
    "\"btw\": \"by the way\",\n",
    "\"cid\": \"crying in disgrace\",\n",
    "\"cnp\": \"continued in my next post\",\n",
    "\"cp\": \"chat post\",\n",
    "\"cu\": \"see you\",\n",
    "\"cul\": \"see you later\",\n",
    "\"cul8r\": \"see you later\",\n",
    "\"cya\": \"bye\",\n",
    "\"cyo\": \"see you online\",\n",
    "\"dbau\": \"doing business as usual\",\n",
    "\"fud\": \"fear, uncertainty, and doubt\",\n",
    "\"fwiw\": \"for what it's worth\",\n",
    "\"fyi\": \"for your information\",\n",
    "\"g\": \"grin\",\n",
    "\"g2g\": \"got to go\",\n",
    "\"ga\": \"go ahead\",\n",
    "\"gal\": \"get a life\",\n",
    "\"gf\": \"girlfriend\",\n",
    "\"gfn\": \"gone for now\",\n",
    "\"gmbo\": \"giggling my butt off\",\n",
    "\"gmta\": \"great minds think alike\",\n",
    "\"h8\": \"hate\",\n",
    "\"hagn\": \"have a good night\",\n",
    "\"hdop\": \"help delete online predators\",\n",
    "\"hhis\": \"hanging head in shame\",\n",
    "\"iac\": \"in any case\",\n",
    "\"ianal\": \"I am not a lawyer\",\n",
    "\"ic\": \"I see\",\n",
    "\"idk\": \"I don't know\",\n",
    "\"imao\": \"in my arrogant opinion\",\n",
    "\"imnsho\": \"in my not so humble opinion\",\n",
    "\"imo\": \"in my opinion\",\n",
    "\"iow\": \"in other words\",\n",
    "\"ipn\": \"I’m posting naked\",\n",
    "\"irl\": \"in real life\",\n",
    "\"jk\": \"just kidding\",\n",
    "\"l8r\": \"later\",\n",
    "\"ld\": \"later, dude\",\n",
    "\"ldr\": \"long distance relationship\",\n",
    "\"llta\": \"lots and lots of thunderous applause\",\n",
    "\"lmao\": \"laugh my ass off\",\n",
    "\"lmirl\": \"let's meet in real life\",\n",
    "\"lol\": \"laugh out loud\",\n",
    "\"ltr\": \"longterm relationship\",\n",
    "\"lulab\": \"love you like a brother\",\n",
    "\"lulas\": \"love you like a sister\",\n",
    "\"luv\": \"love\",\n",
    "\"m/f\": \"male or female\",\n",
    "\"m8\": \"mate\",\n",
    "\"milf\": \"mother I would like to fuck\",\n",
    "\"mkt\": \"market\",\n",
    "\"oll\": \"online love\",\n",
    "\"omg\": \"oh my god\",\n",
    "\"otoh\": \"on the other hand\",\n",
    "\"pir\": \"parent in room\",\n",
    "\"ppl\": \"people\",\n",
    "\"r\": \"are\",\n",
    "\"rofl\": \"roll on the floor laughing\",\n",
    "\"rpg\": \"role playing games\",\n",
    "\"ru\": \"are you\",\n",
    "\"shid\": \"slaps head in disgust\",\n",
    "\"somy\": \"sick of me yet\",\n",
    "\"sot\": \"short of time\",\n",
    "\"thanx\": \"thanks\",\n",
    "\"thx\": \"thanks\",\n",
    "\"ttyl\": \"talk to you later\",\n",
    "\"u\": \"you\",\n",
    "\"ur\": \"you are\",\n",
    "\"uw\": \"you’re welcome\",\n",
    "\"wb\": \"welcome back\",\n",
    "\"wfm\": \"works for me\",\n",
    "\"wibni\": \"wouldn't it be nice if\",\n",
    "\"wtf\": \"what the fuck\",\n",
    "\"wtg\": \"way to go\",\n",
    "\"wtgp\": \"want to go private\",\n",
    "\"yrs\": \"years\",\n",
    "\"ym\": \"young man\",\n",
    "\"gr8\": \"great\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_words(text, dictionary):\n",
    "    \"\"\"\n",
    "    Method to replace a word with a word from the dictionary.\n",
    "    The dictionary will have the word to be replaced as key and the new word as value\n",
    "    \"\"\"\n",
    "    for word in text.split():\n",
    "        if word.lower() in dictionary:\n",
    "            if word.lower() in text.split():\n",
    "                text = text.replace(word, dictionary[word.lower()])\n",
    "                print(\"Old: \"+word)\n",
    "                print(\"New: \"+text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-precessing function\n",
    "def preprocess_text(data, col_name):\n",
    "    \n",
    "    #converting string to lower case\n",
    "    data[col_name] = data[col_name].str.lower()\n",
    "    \n",
    "    #remove user handles\n",
    "    data[col_name] = data[col_name].apply(lambda row:remove_pattern(row, \"@[\\w]*\"))\n",
    "    \n",
    "    #converting html characters to strings\n",
    "    data[col_name] = data[col_name].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())\n",
    "    \n",
    "    #converting emojis to the string they represent\n",
    "    data[col_name] = data[col_name].apply(lambda x: handle_emojis(x))\n",
    "    \n",
    "     #removing URLs from the tweets\n",
    "    data[col_name]  = data[col_name].apply(lambda x: re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', ' URL ', x))\n",
    "    \n",
    "    #converting abbreviations to their full forms\n",
    "    data[col_name] = data[col_name].replace('[...…]','').str.split().apply(lambda x: ' '.join([short_word_dict.get(e, e) for e in x]))\n",
    "    \n",
    "    # Remove single space remaining at the front of the tweet.\n",
    "    data[col_name] = data[col_name].apply(lambda x: x.lstrip(' '))\n",
    "    \n",
    "    # Remove characters beyond Basic Multilingual Plane (BMP) of Unicode:\n",
    "    data[col_name] = data[col_name].apply(lambda x: ''.join(c for c in x if c <= '\\uFFFF'))\n",
    "    \n",
    "     #removing non-ASCII characters\n",
    "    data[col_name] = data[col_name].apply(lambda x: ''.join([i if ord(i) < 128 else ' ' for i in x]))\n",
    "    \n",
    "    # Remove words with 2 or fewer letters\n",
    "    data[col_name] = data[col_name].apply(lambda x: re.sub(r'\\b\\w{1,2}\\b', '', x))\n",
    "    \n",
    "    # Convert more than 2 letter repetitions to 2 letter\n",
    "    # funnnnny --> funny\n",
    "    data[col_name] = data[col_name].apply(lambda x: re.sub(r'(.)\\1+', r'\\1\\1', x))\n",
    "    \n",
    "    #tokenizing data\n",
    "    data[col_name] = data[col_name].apply(lambda x: nltk.word_tokenize(x))\n",
    "    \n",
    "    #stopwords removal\n",
    "    stop_words = list(set(stopwords.words('english')))+list(punctuation)+['``', \"'s\", \"...\", \"n't\", \"'re\", \"''\"]\n",
    "    data[col_name] = data[col_name].apply(lambda row: [word for word in row if word not in stop_words])\n",
    "    \n",
    "#     # stemming words\n",
    "#     stemmer = PorterStemmer()\n",
    "#     data[col_name] = data[col_name].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "\n",
    "    #lemmatization\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     data[col_name] = data[col_name].apply(lambda x: [lemmatizer.lemmatize(i) for i in x])\n",
    "\n",
    "    \n",
    "    data[col_name] = data[col_name].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1701</td>\n",
       "      <td>#sxswnui #sxsw #apple defining language of tou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851</td>\n",
       "      <td>Learning ab Google doodles! All doodles should...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2689</td>\n",
       "      <td>one of the most in-your-face ex. of stealing t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4525</td>\n",
       "      <td>This iPhone #SXSW app would b pretty awesome i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3604</td>\n",
       "      <td>Line outside the Apple store in Austin waiting...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                              tweet  sentiment\n",
       "0      1701  #sxswnui #sxsw #apple defining language of tou...          1\n",
       "1      1851  Learning ab Google doodles! All doodles should...          1\n",
       "2      2689  one of the most in-your-face ex. of stealing t...          2\n",
       "3      4525  This iPhone #SXSW app would b pretty awesome i...          0\n",
       "4      3604  Line outside the Apple store in Austin waiting...          1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "train_data.dropna(inplace=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_train = preprocess_text(train_data, 'tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = pd.read_csv('data/processed_data.csv')\n",
    "processed_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1701</td>\n",
       "      <td>sxswnui sxsw apple defining language touch dif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851</td>\n",
       "      <td>learning google doodles doodles light funny in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2689</td>\n",
       "      <td>one -your-face stealing show years sxsw apple ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4525</td>\n",
       "      <td>iphone sxsw app would pretty awesome crash eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3604</td>\n",
       "      <td>line outside apple store austin waiting new ip...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>966</td>\n",
       "      <td>technews one lone dude awaits ipad apple sxsw ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1395</td>\n",
       "      <td>sxsw tips prince npr videos toy shopping zucke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8182</td>\n",
       "      <td>user new ubersocial iphone app store includes ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8835</td>\n",
       "      <td>free sxsw sampler itunes link freemusic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>883</td>\n",
       "      <td>think might weekend without seeing ipad case t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                              tweet  sentiment\n",
       "0      1701  sxswnui sxsw apple defining language touch dif...          1\n",
       "1      1851  learning google doodles doodles light funny in...          1\n",
       "2      2689  one -your-face stealing show years sxsw apple ...          2\n",
       "3      4525  iphone sxsw app would pretty awesome crash eve...          0\n",
       "4      3604  line outside apple store austin waiting new ip...          1\n",
       "5       966  technews one lone dude awaits ipad apple sxsw ...          1\n",
       "6      1395  sxsw tips prince npr videos toy shopping zucke...          1\n",
       "7      8182  user new ubersocial iphone app store includes ...          1\n",
       "8      8835            free sxsw sampler itunes link freemusic          2\n",
       "9       883  think might weekend without seeing ipad case t...          2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7506</td>\n",
       "      <td>audience prototyping tools use sketchbooks/sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7992</td>\n",
       "      <td>sxsw send best photos videos .. link citizen_j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>247</td>\n",
       "      <td>pic winning ipad unsix sxsw link cont link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7688</td>\n",
       "      <td>google marissa mayer mobile phone cursor physi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3294</td>\n",
       "      <td>sxsw google maps even cooler thought</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                              tweet\n",
       "0      7506  audience prototyping tools use sketchbooks/sha...\n",
       "1      7992  sxsw send best photos videos .. link citizen_j...\n",
       "2       247         pic winning ipad unsix sxsw link cont link\n",
       "3      7688  google marissa mayer mobile phone cursor physi...\n",
       "4      3294               sxsw google maps even cooler thought"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('data/test_processed.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "X_train = count_vectorizer.fit_transform(processed_train['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7272, 8332)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = count_vectorizer.transform(test_data['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1819, 8332)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit and predict on upsampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression(max_iter=7600)\n",
    "lr_model.fit(X_train, processed_train['sentiment'])\n",
    "lr_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1246\n",
       "2     516\n",
       "0      57\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_submit = pd.DataFrame({'tweet_id': test_data['tweet_id'], 'sentiment': lr_pred})\n",
    "to_submit.to_csv('probability_manipulation/lr_pred_basic.csv', index=False)\n",
    "to_submit['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    1113\n",
       "2     568\n",
       "0     136\n",
       "3       2\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = lr_model.predict_proba(X_test)\n",
    "\n",
    "for i in range(0,1819):\n",
    "    prob_0 = probs[i,0]\n",
    "    prob_1 = probs[i,1]\n",
    "    prob_2 = probs[i,2]\n",
    "    prob_3 = probs[i,3]\n",
    "    if prob_3 > 0.3:\n",
    "        probs[i,0] = 0\n",
    "        probs[i,1] = 0\n",
    "        probs[i,2] = 0\n",
    "    if prob_0 > 0.2:\n",
    "        probs[i,3] = 0\n",
    "        probs[i,1] = 0\n",
    "        probs[i,2] = 0\n",
    "    if prob_1 > 0.75:\n",
    "        probs[i,0] = 0\n",
    "        probs[i,2] = 0\n",
    "        probs[i,3] = 0\n",
    "    if prob_2 > 0.4:\n",
    "        probs[i,0] = 0\n",
    "        probs[i,1] = 0\n",
    "        probs[i,3] = 0\n",
    "        \n",
    "final_class_list = []\n",
    "for i in range(0,1819):\n",
    "    prob_0 = probs[i,0]\n",
    "    prob_1 = probs[i,1]\n",
    "    prob_2 = probs[i,2]\n",
    "    prob_3 = probs[i,3]\n",
    "    d = {'0': prob_0, '1': prob_1, '2': prob_2, '3': prob_3}\n",
    "    max_class = max(d, key=d.get)\n",
    "    final_class_list.append(int(max_class))\n",
    "    \n",
    "final_class_arr = np.asarray(final_class_list)\n",
    "\n",
    "to_submit = pd.DataFrame({'tweet_id': test_data['tweet_id'], 'sentiment': final_class_arr})\n",
    "to_submit.to_csv('probability_manipulation/pred_proba.csv', index=False)\n",
    "to_submit['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4309\n",
       "2    2382\n",
       "0     456\n",
       "3     125\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
