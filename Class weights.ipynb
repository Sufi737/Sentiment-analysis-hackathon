{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cv(model, X, y):\n",
    "    f1_scores = []\n",
    "    X_t, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    model.fit(X_t, y_train)\n",
    "    model_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, model_pred))\n",
    "    f1 = f1_score(y_test, model_pred,average=\"weighted\")\n",
    "    print(\"F1 score: \"+str(f1))\n",
    "    f1_scores.append(f1)\n",
    "    return f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text): \n",
    "    tknzr = TweetTokenizer()\n",
    "    return tknzr.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = pd.read_csv('data/processed_data.csv')\n",
    "processed_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = pd.read_csv('data/train_lemmatized.csv')\n",
    "processed_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4309\n",
       "2    2382\n",
       "0     456\n",
       "3     125\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('data/test_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('data/test_lemmatized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "X_train = count_vectorizer.fit_transform(processed_train['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()\n",
    "X_train = tf.fit_transform(processed_train['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7272, 8332)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = count_vectorizer.transform(test_data['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1819, 8332)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=3)\n",
    "data_res, label_res = ros.fit_sample(X_train, processed_train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17236, 8332)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17236,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(max_iter=7600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=7, n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      1425\n",
      "           1       0.73      0.69      0.71      1428\n",
      "           2       0.75      0.71      0.73      1387\n",
      "           3       0.96      1.00      0.98      1448\n",
      "\n",
      "    accuracy                           0.84      5688\n",
      "   macro avg       0.84      0.84      0.84      5688\n",
      "weighted avg       0.84      0.84      0.84      5688\n",
      "\n",
      "F1 score: 0.8396630326323239\n"
     ]
    }
   ],
   "source": [
    "f1_scores = perform_cv(xgb, data_res, label_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6491923836728479"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      1412\n",
      "           1       0.78      0.72      0.75      1450\n",
      "           2       0.77      0.75      0.76      1426\n",
      "           3       0.96      0.99      0.98      1400\n",
      "\n",
      "    accuracy                           0.86      5688\n",
      "   macro avg       0.86      0.86      0.86      5688\n",
      "weighted avg       0.85      0.86      0.86      5688\n",
      "\n",
      "F1 score: 0.8555155603033034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1425\n",
      "           1       0.81      0.67      0.73      1479\n",
      "           2       0.74      0.79      0.77      1380\n",
      "           3       0.94      1.00      0.97      1404\n",
      "\n",
      "    accuracy                           0.86      5688\n",
      "   macro avg       0.85      0.86      0.85      5688\n",
      "weighted avg       0.85      0.86      0.85      5688\n",
      "\n",
      "F1 score: 0.8539231156849446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      1451\n",
      "           1       0.80      0.69      0.74      1445\n",
      "           2       0.76      0.79      0.78      1405\n",
      "           3       0.95      1.00      0.97      1387\n",
      "\n",
      "    accuracy                           0.87      5688\n",
      "   macro avg       0.86      0.87      0.86      5688\n",
      "weighted avg       0.86      0.87      0.86      5688\n",
      "\n",
      "F1 score: 0.8622463214279092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1432\n",
      "           1       0.75      0.71      0.73      1388\n",
      "           2       0.78      0.75      0.76      1436\n",
      "           3       0.96      0.99      0.98      1432\n",
      "\n",
      "    accuracy                           0.86      5688\n",
      "   macro avg       0.85      0.86      0.85      5688\n",
      "weighted avg       0.85      0.86      0.85      5688\n",
      "\n",
      "F1 score: 0.8547960713870288\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1446\n",
      "           1       0.77      0.70      0.74      1401\n",
      "           2       0.78      0.77      0.78      1448\n",
      "           3       0.96      0.99      0.97      1393\n",
      "\n",
      "    accuracy                           0.86      5688\n",
      "   macro avg       0.86      0.86      0.86      5688\n",
      "weighted avg       0.86      0.86      0.86      5688\n",
      "\n",
      "F1 score: 0.859824413951411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      1410\n",
      "           1       0.75      0.70      0.72      1422\n",
      "           2       0.76      0.75      0.75      1432\n",
      "           3       0.97      0.99      0.98      1424\n",
      "\n",
      "    accuracy                           0.86      5688\n",
      "   macro avg       0.85      0.86      0.85      5688\n",
      "weighted avg       0.85      0.86      0.85      5688\n",
      "\n",
      "F1 score: 0.8530805459082714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      1429\n",
      "           1       0.77      0.70      0.73      1383\n",
      "           2       0.78      0.77      0.78      1452\n",
      "           3       0.97      0.99      0.98      1424\n",
      "\n",
      "    accuracy                           0.86      5688\n",
      "   macro avg       0.86      0.86      0.86      5688\n",
      "weighted avg       0.86      0.86      0.86      5688\n",
      "\n",
      "F1 score: 0.8608089670187583\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95      1367\n",
      "           1       0.77      0.68      0.72      1444\n",
      "           2       0.76      0.76      0.76      1439\n",
      "           3       0.96      0.99      0.97      1438\n",
      "\n",
      "    accuracy                           0.85      5688\n",
      "   macro avg       0.85      0.85      0.85      5688\n",
      "weighted avg       0.85      0.85      0.85      5688\n",
      "\n",
      "F1 score: 0.8490126457468186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1426\n",
      "           1       0.77      0.71      0.74      1430\n",
      "           2       0.77      0.76      0.76      1429\n",
      "           3       0.96      0.99      0.98      1403\n",
      "\n",
      "    accuracy                           0.86      5688\n",
      "   macro avg       0.86      0.86      0.86      5688\n",
      "weighted avg       0.86      0.86      0.86      5688\n",
      "\n",
      "F1 score: 0.8563533981010188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      1419\n",
      "           1       0.77      0.70      0.74      1472\n",
      "           2       0.76      0.75      0.75      1356\n",
      "           3       0.96      0.99      0.97      1441\n",
      "\n",
      "    accuracy                           0.85      5688\n",
      "   macro avg       0.85      0.85      0.85      5688\n",
      "weighted avg       0.85      0.85      0.85      5688\n",
      "\n",
      "F1 score: 0.8518879725663611\n"
     ]
    }
   ],
   "source": [
    "f1_scores = perform_cv(lr_model, data_res, label_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=7600,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.fit(data_res, label_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7506</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7688</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3294</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id  sentiment\n",
       "0      7506          1\n",
       "1      7992          1\n",
       "2       247          1\n",
       "3      7688          2\n",
       "4      3294          2"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_submit = pd.DataFrame({'tweet_id': test_data['tweet_id'], 'sentiment': upsample_pred})\n",
    "to_submit.to_csv('solutions/upsample_pred.csv', index=False)\n",
    "to_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1043\n",
       "2     594\n",
       "0     147\n",
       "3      35\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_submit['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = lr_model.predict_proba(X_test)\n",
    "\n",
    "for i in range(0,1819):\n",
    "    prob_0 = probs[i,0]\n",
    "    prob_1 = probs[i,1]\n",
    "    prob_2 = probs[i,2]\n",
    "    prob_3 = probs[i,3]\n",
    "    if prob_1 > 0.75:\n",
    "        probs[i,3] = 2\n",
    "    if prob_3 > 0.2:\n",
    "        probs[i,3] = 2\n",
    "    if prob_0 > 0.25:\n",
    "        probs[i,0] = 2\n",
    "    if prob_2 > 0.6:\n",
    "        probs[i,2] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.11989038e-02, 8.79853530e-01, 8.40660041e-02, 2.00000000e+00],\n",
       "       [1.03548014e-03, 7.78450651e-01, 5.80816510e-02, 2.00000000e+00],\n",
       "       [7.75008989e-03, 5.38446380e-01, 4.47055992e-01, 6.74753845e-03],\n",
       "       ...,\n",
       "       [1.16471413e-02, 3.40044767e-01, 2.00000000e+00, 6.83330723e-03],\n",
       "       [2.09987891e-01, 4.45039459e-01, 2.49126504e-01, 9.58461452e-02],\n",
       "       [3.60151946e-03, 9.13358004e-01, 4.59061361e-02, 2.00000000e+00]])"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_class_list = []\n",
    "for i in range(0,1819):\n",
    "    prob_0 = probs[i,0]\n",
    "    prob_1 = probs[i,1]\n",
    "    prob_2 = probs[i,2]\n",
    "    prob_3 = probs[i,3]\n",
    "    d = {'0': prob_0, '1': prob_1, '2': prob_2, '3': prob_3}\n",
    "    max_class = max(d, key=d.get)\n",
    "    final_class_list.append(int(max_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_class_arr = np.asarray(final_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1819,)"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_class_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    640\n",
       "2    565\n",
       "1    408\n",
       "0    206\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_submit = pd.DataFrame({'tweet_id': test_data['tweet_id'], 'sentiment': final_class_arr})\n",
    "to_submit.to_csv('probability_manipulation/pred_proba.csv', index=False)\n",
    "to_submit['sentiment'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
